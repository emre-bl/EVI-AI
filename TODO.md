# Legend:
* ğŸ« --> must be added to project
* ğŸ’¡ --> will be discussed
* ğŸ“ --> tests needed for improvement
* âœ… --> done
* âŒ --> not done

# YOLO-SIDE
- new YOLO models for different speed/precision can be added from: https://docs.ultralytics.com/models/yolov8/#key-features ğŸ’¡
- different verbose types(drawing bounding boxes or showing available ways) can be added ğŸ’¡

# LLM-SIDE
- Local LLM testing must done ğŸ«
- LLM prompts should be tried and improved if needed ğŸ“

# DEPTH-MODELS-SIDE
- best pretrained models on telegram must be selected (one for city and one for indoor cases) ğŸ«
- inference code for both models must be created ğŸ«
- 2 depth models(one for cityscapes one for indoors) should be included in app, model selection will be left to user. ğŸ“

# RTSP-SIDE
- images can be sent as json objects ğŸ’¡
- additional information(original image size, YOLO version, DEPTH model type etc.) about pipeline usage must be sent also ğŸ«
- images can sent in base64 ğŸ’¡
- problem with already open connections must be solved ğŸ«

# ENTIRE CODE
- temporary function importing must be added for image receiving functions ğŸ«
- functions must be imported from their relative path to user.py and server.py ğŸ«
- whole pipeline must be merged together ğŸ«
- text-to-speech can be better, maybe it will work better in phone ğŸ’¡
- whole code should be able to controlled via yaml file ğŸ’¡

# USER-SIDE-PIPELINE
- 1-) capture the frame from camera âœ…
- 2-) send the captured frame to server âœ…
- 3-) wait for servers response âœ…
- 4-) give audio feedback to user in all languagesâŒ

# APP-SIDE-PIPELINE
- 1-) wait for images from user âœ…
- 2-) send image to YOLO âœ…
- 3-) send image to DEPTHMODEL âŒ
- 4-) merge YOLO and DEPTHMODEL output âŒ
- 5-) concatanate merged output string with ready LLM prompt âŒ
- 6-) send new prompt to LLM API âŒ
- 7-) return the answer of LLM to image_sender âŒ