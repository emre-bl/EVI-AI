# Legend:
* ğŸ« --> must be added to project
* ğŸ’¡ --> will be discussed
* ğŸ“ --> tests needed for improvement
* âœ… --> done
* âŒ --> not done

# YOLO-SIDE
- new YOLO models for different speed/precision can be added from: https://docs.ultralytics.com/models/yolov8/#key-features ğŸ’¡
- different verbose types(drawing bounding boxes or showing available ways) can be added ğŸ’¡

# LLM-SIDE
- Local LLM testing must done ğŸ«
- LLM prompts should be tried and improved if needed ğŸ“

# DEPTH-MODELS-SIDE
- one functional depth model must implemented ğŸ«
- 2 depth models(one for cityscapes one for indoors) could be included, model selection will be left to user. ğŸ’¡

# RTSP-SIDE
- images can be sent as json objects âœ…
- additional information(original image size, YOLO version, DEPTH model type etc.) about pipeline usage must be sent also âœ…
- images can sent in base64 âœ…
- problem with already open connections must be solved âœ…
- additional information(users feedback delay second preference, prefered YOLO models etc.) can be send from user to server at initial connection ğŸ’¡

# ENTIRE CODE
- functions should be imported from their relative path to user.py and server.py ğŸ“
- whole pipeline must be merged together ğŸ«
- text-to-speech can be better, maybe it will work better in phone ğŸ’¡
- whole code should be able to controlled via yaml file ğŸ’¡

# USER-SIDE-PIPELINE
- 1-) capture the frame from camera âœ…
- 2-) send the captured frame to server âœ…
- 3-) wait for servers response âœ…
- 4-) give audio feedback to user in all languagesâŒ

# APP-SIDE-PIPELINE
- 1-) wait for images from user âœ…
- 2-) send image to YOLO âœ…
- 3-) send image to DEPTHMODEL âŒ
- 4-) merge YOLO and DEPTHMODEL output âŒ
- 5-) concatanate merged output string with ready LLM prompt âŒ
- 6-) send new prompt to LLM API âŒ
- 7-) return the answer of LLM to image_sender âŒ
