{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 YOLO local image'lerden çalıştırılacak\n",
    "2 YOLO local videodan opencv ile frame okuyarak çalıştırılacak\n",
    "3 YOLO local videodan gstreamer ile frame okuyarak çalıştırılacak\n",
    "\n",
    "4 RGB2Depth modelleri denenecek en iyisi bulunacak\n",
    "5 RGB2D modeli local image'lerden çalıştırılacak\n",
    "6 RGB2D modeli local videodan gstreamer ile frame okuyarak çalıştırılacak\n",
    "\n",
    "7 YOLO ve RGB2D modeli birlikte çalıştırılacak\n",
    "8 modellerin çıktıları rapordaki gibi formatlanacak\n",
    "\n",
    "9 örnek çıktılarla prompt denemeleri yapılacak \n",
    "10 LLM olarak gruba attığım python librarysi incelenecek\n",
    "11 LLMden alınan çıktı text2speech olarak ayarlanacak\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv.namedWindow('Screen Image', cv.WINDOW_NORMAL)\n",
    "\n",
    "cv.imshow('Screen Image', screen)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/meric/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m ❌ AutoUpdate skipped (offline)\n",
      "YOLOv5 🚀 2023-6-14 Python-3.9.13 torch-2.0.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_bboxs(img, result, threshold):\n",
    "    object_ids = []\n",
    "    id_counter = 1\n",
    "    for bbox, label, conf in zip(result.xyxy[0][:,:4], result.pred[0][:,5], result.pred[0][:,4]):\n",
    "        if conf >= threshold:\n",
    "            x1, y1, x2, y2 = map(int, bbox[:4])\n",
    "            class_name = result.names[int(label)]\n",
    "            \n",
    "            cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 7)\n",
    "            \n",
    "            label_text = str(id_counter) + \"-\" + str(class_name) + \": {:.2f}\".format(conf)\n",
    "            cv.putText(img, label_text, (x1, y1 - 10), cv.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 6)\n",
    "            \n",
    "            object_ids.append(id_counter)\n",
    "            id_counter = id_counter + 1\n",
    "        else:\n",
    "            # -1 id means model is not confident enough\n",
    "            object_ids.append(-1)\n",
    "\n",
    "    return object_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(img, result):\n",
    "    # list of objects center pixels offsets according to images center point\n",
    "    # negative: left/up\n",
    "    # positive: right/down\n",
    "    # X:row axis, determines how high or low an object is\n",
    "    # Y:column axis, determines how left or right an object is\n",
    "    im_s = img.shape\n",
    "\n",
    "    # finding the angles of object according to camera, most left(y=-1):-50 degrees, most right(y=+1):+50 degrees\n",
    "    object_angles = [(\n",
    "                    round((((c[1] + c[3])/2 - im_s[0]/2) / (im_s[0]/2) * 5).item())*10,\n",
    "                    round((((c[0] + c[2])/2 - im_s[1]/2) / (im_s[1]/2) * 5).item())*10)\n",
    "                    for c in result.xyxy[0][:,:4]]\n",
    "\n",
    "    return object_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./YOLO_test_images\"\n",
    "images = os.listdir(folder_path)\n",
    "\n",
    "for img_name in images:\n",
    "    img = cv.imread(os.path.join(folder_path, img_name))\n",
    "    \n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\tCLASS\tLEFT-RIGHT ANGLE\n",
      "1 \t person     \t (30, -20)\n",
      "2 \t person     \t (30, -20)\n",
      "3 \t bench     \t (30, 20)\n",
      "4 \t person     \t (30, -20)\n",
      "5 \t person     \t (20, 0)\n",
      "6 \t person     \t (30, 40)\n",
      "7 \t person     \t (20, 0)\n",
      "8 \t person     \t (20, -10)\n",
      "9 \t person     \t (30, -10)\n",
      "10 \t person     \t (20, -10)\n",
      "11 \t person     \t (30, 10)\n",
      "12 \t person     \t (30, 20)\n",
      "13 \t person     \t (20, 10)\n",
      "14 \t person     \t (20, 0)\n",
      "-1 \t person     \t (20, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"ID\\tCLASS\\tLEFT-RIGHT ANGLE\")\n",
    "for id, l, d in zip(object_ids, object_labels, object_angles):\n",
    "    print(id,\"\\t\",l,\"   \",\"\\t\",d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './YOLO_test_videos/video1.webm'\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "frame_rate = 5\n",
    "frame_interval = 1 / frame_rate\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_to_wait = max(0, frame_interval - elapsed_time)\n",
    "    time.sleep(time_to_wait)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gstreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video file.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10550/1974543535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: Could not open video file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mframe_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "video_path = './YOLO_test_videos/video1.webm'\n",
    "pipeline = f'filesrc location={video_path} ! matroskademux ! vp8dec ! videoconvert ! appsink'\n",
    "\n",
    "cap = cv.VideoCapture(pipeline, cv.CAP_GSTREAMER)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    print(8/0)\n",
    "\n",
    "frame_rate = 5\n",
    "frame_interval = 1 / frame_rate\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_to_wait = max(0, frame_interval - elapsed_time)\n",
    "    time.sleep(time_to_wait)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
