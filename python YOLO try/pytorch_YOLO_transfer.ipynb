{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "1 YOLO local image'lerden Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "2 YOLO local videodan opencv ile frame okuyarak Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "3 YOLO local videodan gstreamer ile frame okuyarak Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "\n",
    "4 RGB2Depth modelleri denenecek en iyisi bulunacak\n",
    "5 RGB2D modeli local image'lerden Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "6 RGB2D modeli local videodan gstreamer ile frame okuyarak Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "\n",
    "7 YOLO ve RGB2D modeli birlikte Ã§alÄ±ÅŸtÄ±rÄ±lacak\n",
    "8 modellerin Ã§Ä±ktÄ±larÄ± rapordaki gibi formatlanacak\n",
    "\n",
    "9 Ã¶rnek Ã§Ä±ktÄ±larla prompt denemeleri yapÄ±lacak \n",
    "10 LLM olarak gruba attÄ±ÄŸÄ±m python librarysi incelenecek\n",
    "11 LLMden alÄ±nan Ã§Ä±ktÄ± text2speech olarak ayarlanacak\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "cv.namedWindow('Screen Image', cv.WINDOW_NORMAL)\n",
    "\n",
    "cv.imshow('Screen Image', screen)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/meric/.cache/torch/hub/ultralytics_yolov5_master\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement \"gitpython>=3.1.30\" not found, attempting AutoUpdate...\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m âŒ AutoUpdate skipped (offline)\n",
      "YOLOv5 ðŸš€ 2023-6-14 Python-3.9.13 torch-2.0.0+cu117 CPU\n",
      "\n",
      "Fusing layers... \n",
      "YOLOv5s summary: 213 layers, 7225885 parameters, 0 gradients\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import time\n",
    "\n",
    "\n",
    "model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def put_bboxs(img, result, threshold):\n",
    "    object_ids = []\n",
    "    id_counter = 1\n",
    "    for bbox, label, conf in zip(result.xyxy[0][:,:4], result.pred[0][:,5], result.pred[0][:,4]):\n",
    "        if conf >= threshold:\n",
    "            x1, y1, x2, y2 = map(int, bbox[:4])\n",
    "            class_name = result.names[int(label)]\n",
    "            \n",
    "            cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0), 7)\n",
    "            \n",
    "            label_text = str(id_counter) + \"-\" + str(class_name) + \": {:.2f}\".format(conf)\n",
    "            cv.putText(img, label_text, (x1, y1 - 10), cv.FONT_HERSHEY_SIMPLEX, 1.5, (0, 0, 0), 6)\n",
    "            \n",
    "            object_ids.append(id_counter)\n",
    "            id_counter = id_counter + 1\n",
    "        else:\n",
    "            # -1 id means model is not confident enough\n",
    "            object_ids.append(-1)\n",
    "\n",
    "    return object_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_angles(img, result):\n",
    "    # list of objects center pixels offsets according to images center point\n",
    "    # negative: left/up\n",
    "    # positive: right/down\n",
    "    # X:row axis, determines how high or low an object is\n",
    "    # Y:column axis, determines how left or right an object is\n",
    "    im_s = img.shape\n",
    "\n",
    "    # finding the angles of object according to camera, most left(y=-1):-50 degrees, most right(y=+1):+50 degrees\n",
    "    object_angles = [(\n",
    "                    round((((c[1] + c[3])/2 - im_s[0]/2) / (im_s[0]/2) * 5).item())*10,\n",
    "                    round((((c[0] + c[2])/2 - im_s[1]/2) / (im_s[1]/2) * 5).item())*10)\n",
    "                    for c in result.xyxy[0][:,:4]]\n",
    "\n",
    "    return object_angles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_img(img):\n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"./YOLO_test_images\"\n",
    "images = os.listdir(folder_path)\n",
    "\n",
    "for img_name in images:\n",
    "    img = cv.imread(os.path.join(folder_path, img_name))\n",
    "    \n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    display_img(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ID\tCLASS\tLEFT-RIGHT ANGLE\n",
      "1 \t person     \t (30, -20)\n",
      "2 \t person     \t (30, -20)\n",
      "3 \t bench     \t (30, 20)\n",
      "4 \t person     \t (30, -20)\n",
      "5 \t person     \t (20, 0)\n",
      "6 \t person     \t (30, 40)\n",
      "7 \t person     \t (20, 0)\n",
      "8 \t person     \t (20, -10)\n",
      "9 \t person     \t (30, -10)\n",
      "10 \t person     \t (20, -10)\n",
      "11 \t person     \t (30, 10)\n",
      "12 \t person     \t (30, 20)\n",
      "13 \t person     \t (20, 10)\n",
      "14 \t person     \t (20, 0)\n",
      "-1 \t person     \t (20, 0)\n"
     ]
    }
   ],
   "source": [
    "print(\"ID\\tCLASS\\tLEFT-RIGHT ANGLE\")\n",
    "for id, l, d in zip(object_ids, object_labels, object_angles):\n",
    "    print(id,\"\\t\",l,\"   \",\"\\t\",d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "video_path = './YOLO_test_videos/video1.webm'\n",
    "cap = cv.VideoCapture(video_path)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    exit()\n",
    "\n",
    "frame_rate = 5\n",
    "frame_interval = 1 / frame_rate\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_to_wait = max(0, frame_interval - elapsed_time)\n",
    "    time.sleep(time_to_wait)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gstreamer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Could not open video file.\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10550/1974543535.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misOpened\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error: Could not open video file.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mframe_rate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "video_path = './YOLO_test_videos/video1.webm'\n",
    "pipeline = f'filesrc location={video_path} ! matroskademux ! vp8dec ! videoconvert ! appsink'\n",
    "\n",
    "cap = cv.VideoCapture(pipeline, cv.CAP_GSTREAMER)\n",
    "\n",
    "if not cap.isOpened():\n",
    "    print(\"Error: Could not open video file.\")\n",
    "    print(8/0)\n",
    "\n",
    "frame_rate = 5\n",
    "frame_interval = 1 / frame_rate\n",
    "\n",
    "while True:\n",
    "    start_time = time.time()\n",
    "    ret, img = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    result = model(img)\n",
    "\n",
    "    object_ids = put_bboxs(img, result, 0.60)\n",
    "    object_angles = calculate_angles(img, result)\n",
    "    object_labels = [result.names[int(l)] for l in result.pred[0][:,5]]\n",
    "    \n",
    "    cv.namedWindow('result', cv.WINDOW_NORMAL)\n",
    "    cv.imshow('result', img)\n",
    "\n",
    "    if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    time_to_wait = max(0, frame_interval - elapsed_time)\n",
    "    time.sleep(time_to_wait)\n",
    "\n",
    "cap.release()\n",
    "cv.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap.isOpened()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
