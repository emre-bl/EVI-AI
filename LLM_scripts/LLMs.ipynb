{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# account for deprecation of LLM model\n",
    "import datetime\n",
    "# Get the current date\n",
    "current_date = datetime.datetime.now().date()\n",
    "\n",
    "# Define the date after which the model should be set to \"gpt-3.5-turbo\"\n",
    "target_date = datetime.date(2024, 6, 12)\n",
    "\n",
    "# Set the model variable based on the current date\n",
    "if current_date > target_date:\n",
    "    llm_model = \"gpt-3.5-turbo\"\n",
    "else:\n",
    "    llm_model = \"gpt-3.5-turbo-0301\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=llm_model):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prompt generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ways = {}\n",
    "angles = [list(range(-65,-45)),list(range(-45,-25)),list(range(-25,-10)),list(range(-10,10)),list(range(10,25)),list(range(25,45)),list(range(45,65))]\n",
    "directions = [\"full left\",\"half left\",\"slightly left\",\"forward\",\"slightly right\",\"half right\",\"full right\"]\n",
    "for l,w in zip(angles,directions):\n",
    "    ways.update({k:w for k in l})\n",
    "\n",
    "no_yolo_example_output = [(1, 25, 0), (2, -30, 1), (7, 40, 2)]\n",
    "yes_yolo_example_output = [(1, 25, 0, \"Tree\"), (2, -30, 1, \"Car\"), (7, 40, 2, \"Table\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generates prompt by merging infos from models outputs\n",
    "def generate_prompt(model_out):\n",
    "    if len(model_out) == 0:\n",
    "        return \"no obstacle detected, go forward\"\n",
    "\n",
    "    state_str = \"\"\n",
    "    closed_directions = set()\n",
    "    \n",
    "    if len(model_out[0]) == 3: # yolo didnt detect anything\n",
    "        for i in model_out:\n",
    "            closed_directions.add(ways[i[1]])\n",
    "            state_str = state_str + (\"obstacle at \" + str(i[0]) + \" meters ahead at \" + str(ways[i[1]])) + \"\\n\"\n",
    "    else: # yolo detected something\n",
    "        for i in model_out:\n",
    "            closed_directions.add(ways[i[1]])\n",
    "            state_str = state_str + (i[3] + \" at \" + str(i[0]) + \" meters ahead at \" + str(ways[i[1]])) + \"\\n\"\n",
    "\n",
    "    if \"forward\" not in closed_directions:\n",
    "        recommended_direction = \"forward\"\n",
    "    else:\n",
    "        open_directions = [x for x in directions if x not in closed_directions]\n",
    "        recommended_direction = random.choice(open_directions)\n",
    "\n",
    "    with open(\"../LLM_prompts/ready_prompt\", 'r') as file:\n",
    "        ready_prompy = file.read()\n",
    "    state_str = ready_prompy + state_str + \"user should go \" + recommended_direction\n",
    "    state_str = state_str + \"\\n\\nNow write a short sentence to guide the user.\"\n",
    "\n",
    "    return state_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a system to help blind people, this system captures the obstacles ahead the user via camera and calculates how far and how many angles left or right are this obstacles from user. You should guide the user. Now I will provide the outputs of this system and you will give clear instructions based on where are the obstacles and guide the user with short sentences, don’t output anything except guidance sentences. Here is the captured information of the scene(output only short sentences to guide user):\n",
      "\n",
      "obstacle at 1 meters ahead at half right\n",
      "obstacle at 2 meters ahead at half left\n",
      "obstacle at 7 meters ahead at half right\n",
      "user should go forward\n",
      "\n",
      "Now write a short sentence to guide the user.\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(no_yolo_example_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There is a system to help blind people, this system captures the obstacles ahead the user via camera and calculates how far and how many angles left or right are this obstacles from user. You should guide the user. Now I will provide the outputs of this system and you will give clear instructions based on where are the obstacles and guide the user with short sentences, don’t output anything except guidance sentences. Here is the captured information of the scene(output only short sentences to guide user):\n",
      "\n",
      "Tree at 1 meters ahead at half right\n",
      "Car at 2 meters ahead at half left\n",
      "Table at 7 meters ahead at half right\n",
      "user should go forward\n",
      "\n",
      "Now write a short sentence to guide the user.\n"
     ]
    }
   ],
   "source": [
    "print(generate_prompt(yes_yolo_example_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
